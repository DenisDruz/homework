{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DenisDruz/homework/blob/main/Parsing_hw2_DruzDK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSRHGrfg_dpE"
      },
      "outputs": [],
      "source": [
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install pandas\n",
        "\n",
        "import requests as rq\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### шаг 1"
      ],
      "metadata": {
        "id": "F-WJ-h_PA9Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_page = ['https://sysblok.ru', ]\n",
        "\n",
        "for p in range(2, 17):\n",
        "  url = 'https://sysblok.ru' + '/page/' + str(p)\n",
        "  all_page.append(url)\n",
        "\n",
        "print(*all_page, sep='\\n')"
      ],
      "metadata": {
        "id": "1EZIxFPfAeV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### шаг 2"
      ],
      "metadata": {
        "id": "XeIBEKGyA-pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_links = []\n",
        "\n",
        "for url in all_page:\n",
        "  page = rq.get(url)\n",
        "  page.encoding = 'utf-8'\n",
        "  soup = BeautifulSoup(page.text, features='html.parser')\n",
        "  print(url)\n",
        "  print(page.status_code)\n",
        "  for l in soup.find_all('a'):\n",
        "    if l.parent.name == 'h2' and l.get('href') not in all_links:\n",
        "      all_links.append(l.get('href'))\n",
        "\n",
        "print(*all_links, sep='\\n')\n",
        "print(len(all_links))"
      ],
      "metadata": {
        "id": "x9ti7TfWA7VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### шаг 3"
      ],
      "metadata": {
        "id": "tMfZa9Y-Bbtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "link0 = all_links[555]\n",
        "\n",
        "page0 = rq.get(link0)\n",
        "soup0 = BeautifulSoup(page0.text, features='html.parser')\n",
        "print(soup0.prettify())"
      ],
      "metadata": {
        "id": "DAjgSGOYdGP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_date = soup0.find_all('meta', {'property' : 'article:published_time'})[0].attrs['content']\n",
        "date = raw_date[0:10]\n",
        "print(date)"
      ],
      "metadata": {
        "id": "8bFB7G4uB6b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = soup0.find('h1', {'class' : 'entry-title'}).text\n",
        "print(title)"
      ],
      "metadata": {
        "id": "sWIRCUdMCAOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text  = [soup0.find('p', {'class' : 'entry-lead'}).text, ]\n",
        "\n",
        "for i in soup0.find_all('p'):\n",
        "  if i.parent.name == 'article':\n",
        "    text.append(i.text)\n",
        "\n",
        "final_str = '\\n'.join(text)\n",
        "final_text = final_str.lstrip()\n",
        "\n",
        "print(final_text)"
      ],
      "metadata": {
        "id": "ZbJx5m49CCrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "author = soup0.find_all('meta', {'name' : 'author'})[0].attrs['content']\n",
        "print(author)"
      ],
      "metadata": {
        "id": "ZId6Z8_hCUXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category = soup0.find('a', {'rel' : 'category'}).text\n",
        "print(category)"
      ],
      "metadata": {
        "id": "l5mSYWsPCoBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### шаг 4"
      ],
      "metadata": {
        "id": "_Si6KFXkDV9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def GetNews(link0):\n",
        "  page0 = rq.get(link0)\n",
        "  soup0 = BeautifulSoup(page0.text, features='html.parser')\n",
        "  raw_date = soup0.find_all('meta', {'property' : 'article:published_time'})[0].attrs['content']\n",
        "  date = raw_date[0:10]\n",
        "  title = soup0.find('h1', {'class' : 'entry-title'}).text\n",
        "  text  = [soup0.find('p', {'class' : 'entry-lead'}).text, ]\n",
        "  for i in soup0.find_all('p'):\n",
        "    if i.parent.name == 'article':\n",
        "      text.append(i.text)\n",
        "  final_str = '\\n'.join(text)\n",
        "  final_text = final_str.lstrip()\n",
        "  author = soup0.find_all('meta', {'name' : 'author'})[0].attrs['content']\n",
        "  category = soup0.find('a', {'rel' : 'category'}).text\n",
        "  return link0, author, date, title, category, final_text\n"
      ],
      "metadata": {
        "id": "E8iEHxY7DYq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news = []\n",
        "\n",
        "for link in all_links:\n",
        "  try:\n",
        "    new = GetNews(link)\n",
        "    news.append(new)\n",
        "  except:\n",
        "    print(f'Материал по ссылке {link} не спарсился.')\n",
        "\n",
        "print('Парсинг завершен!')"
      ],
      "metadata": {
        "id": "Tp4tcVgGDeJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### шаг 5"
      ],
      "metadata": {
        "id": "i2gKsPgUDkMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(news)\n",
        "df.columns = ['link', 'author', 'date', 'title', 'category', 'text']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5Aj9qgg8DjiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel('sysblok.ru_parsing.xlsx')"
      ],
      "metadata": {
        "id": "q_fpJ3f1DqvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Готово!\n",
        "Загрузите ваш код и собранные новости на GitHub"
      ],
      "metadata": {
        "id": "0lXQWScoDrFm"
      }
    }
  ]
}